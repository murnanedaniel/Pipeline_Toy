Using  cuda
[tensor([[[[-0.4745, -0.5765, -0.6471,  ..., -0.4667, -0.5137, -0.3490],
          [ 0.0667, -0.3333, -0.5843,  ..., -0.2863, -0.5059, -0.2784],
          [ 0.1843, -0.0824, -0.4196,  ...,  0.0039, -0.1765, -0.0196],
          ...,
          [ 0.0745,  0.0118, -0.0745,  ..., -0.0039,  0.0431,  0.0745],
          [ 0.0902,  0.0431, -0.0196,  ...,  0.0196,  0.0431,  0.0667],
          [ 0.0510,  0.0196, -0.0118,  ...,  0.0353,  0.1137,  0.1216]],

         [[-0.5451, -0.4824, -0.6157,  ..., -0.5294, -0.4353, -0.3412],
          [-0.2471, -0.4275, -0.5529,  ..., -0.5843, -0.5373, -0.4431],
          [-0.2392, -0.4588, -0.5843,  ..., -0.3412, -0.3725, -0.3020],
          ...,
          [-0.0196, -0.0824, -0.2000,  ..., -0.0745, -0.0431, -0.0118],
          [-0.0431, -0.0980, -0.1451,  ..., -0.0510, -0.0588, -0.0353],
          [-0.0667, -0.1137, -0.1373,  ..., -0.0510, -0.0118, -0.0039]],

         [[-0.8275, -0.8196, -0.8588,  ..., -0.8824, -0.8667, -0.7882],
          [-0.6784, -0.8275, -0.8510,  ..., -0.7961, -0.8510, -0.7412],
          [-0.5451, -0.7176, -0.8353,  ..., -0.5373, -0.5765, -0.4980],
          ...,
          [-0.0824, -0.2000, -0.2627,  ..., -0.0745, -0.0745, -0.0353],
          [-0.1373, -0.1765, -0.2314,  ..., -0.0431, -0.0588, -0.0588],
          [-0.1765, -0.2078, -0.2549,  ..., -0.1137, -0.0431, -0.0431]]],


        [[[-0.0588, -0.0902, -0.0980,  ..., -0.2000, -0.0196,  0.1843],
          [-0.0431, -0.0824, -0.0745,  ..., -0.1529,  0.0902,  0.1294],
          [-0.0667, -0.1059, -0.0902,  ..., -0.1294,  0.1059,  0.0196],
          ...,
          [-0.5843, -0.6941, -0.7176,  ..., -0.4902, -0.3882, -0.2784],
          [-0.6000, -0.6235, -0.6000,  ..., -0.1922, -0.2078, -0.2078],
          [-0.3725, -0.3804, -0.3569,  ..., -0.1765, -0.1765, -0.1843]],

         [[ 0.2157,  0.2235,  0.2235,  ...,  0.1137,  0.2000,  0.3569],
          [ 0.2549,  0.2471,  0.2549,  ...,  0.1608,  0.3255,  0.3255],
          [ 0.2392,  0.2235,  0.2471,  ...,  0.1843,  0.3490,  0.2314],
          ...,
          [-0.4588, -0.5686, -0.5922,  ..., -0.3176, -0.1765, -0.0667],
          [-0.4118, -0.4353, -0.4118,  ..., -0.0118, -0.0039,  0.0039],
          [-0.1922, -0.2000, -0.1843,  ..., -0.0039,  0.0118, -0.0039]],

         [[ 0.5608,  0.5922,  0.6078,  ...,  0.4353,  0.4745,  0.6078],
          [ 0.6549,  0.6784,  0.6941,  ...,  0.5137,  0.6235,  0.5843],
          [ 0.6784,  0.7020,  0.7176,  ...,  0.5451,  0.6627,  0.5059],
          ...,
          [-0.4902, -0.6000, -0.6314,  ..., -0.2706, -0.1294, -0.0275],
          [-0.4824, -0.4980, -0.4745,  ...,  0.0196,  0.0353,  0.0275],
          [-0.2471, -0.2549, -0.2314,  ...,  0.0275,  0.0431,  0.0275]]],


        [[[-0.2863, -0.3569, -0.2627,  ..., -0.3647, -0.4667, -0.4275],
          [-0.2314, -0.2706, -0.1843,  ..., -0.3804, -0.4431, -0.3333],
          [-0.2157, -0.2627, -0.2392,  ..., -0.2627, -0.3255, -0.2549],
          ...,
          [ 0.1216,  0.0667,  0.1137,  ..., -0.0431, -0.0118, -0.0745],
          [ 0.1137,  0.1451,  0.1765,  ...,  0.0667,  0.0431, -0.0431],
          [ 0.0353,  0.1216,  0.1059,  ...,  0.1137,  0.1137,  0.0275]],

         [[-0.0980, -0.1137, -0.0431,  ..., -0.1373, -0.2471, -0.2000],
          [-0.0353, -0.0353,  0.0196,  ..., -0.1608, -0.2314, -0.1216],
          [-0.0196, -0.0431, -0.0588,  ..., -0.0588, -0.1294, -0.0588],
          ...,
          [ 0.1843,  0.1216,  0.1686,  ...,  0.0510,  0.0588, -0.0431],
          [ 0.1765,  0.2078,  0.2314,  ...,  0.0902,  0.0588, -0.0431],
          [ 0.0902,  0.1765,  0.1608,  ...,  0.0980,  0.0980,  0.0118]],

         [[-0.4275, -0.4588, -0.3804,  ..., -0.4824, -0.5843, -0.5451],
          [-0.3725, -0.3804, -0.3176,  ..., -0.5059, -0.5686, -0.4588],
          [-0.3569, -0.3804, -0.3882,  ..., -0.3961, -0.4588, -0.3882],
          ...,
          [-0.1922, -0.2235, -0.1529,  ..., -0.3098, -0.2392, -0.2941],
          [-0.1686, -0.1294, -0.0980,  ..., -0.2471, -0.2549, -0.3333],
          [-0.2392, -0.1451, -0.1608,  ..., -0.2235, -0.2235, -0.3098]]],


        [[[ 0.2706,  0.2078,  0.1843,  ...,  0.1765, -0.2941, -0.4510],
          [ 0.2078,  0.1451,  0.1294,  ...,  0.1686, -0.1529, -0.1765],
          [ 0.2627,  0.1922,  0.2549,  ...,  0.4118,  0.2235,  0.1059],
          ...,
          [-0.7255, -0.7333, -0.7333,  ..., -0.2392, -0.1686, -0.1529],
          [-0.7333, -0.7333, -0.7333,  ..., -0.0902,  0.0039, -0.0667],
          [-0.7412, -0.7412, -0.7412,  ...,  0.1843,  0.2235,  0.0431]],

         [[ 0.3490,  0.3098,  0.3255,  ..., -0.5137, -0.4118, -0.3569],
          [ 0.2941,  0.2471,  0.2706,  ..., -0.2941, -0.2314, -0.1529],
          [ 0.3020,  0.2392,  0.3176,  ...,  0.1373,  0.0667, -0.0118],
          ...,
          [-0.7098, -0.7176, -0.7176,  ..., -0.1608, -0.1059, -0.1294],
          [-0.7176, -0.7176, -0.7176,  ..., -0.0588,  0.0353, -0.0510],
          [-0.7255, -0.7255, -0.7255,  ...,  0.1843,  0.2314,  0.0667]],

         [[ 0.5686,  0.5529,  0.5608,  ..., -0.3961, -0.2706, -0.1922],
          [ 0.4980,  0.4667,  0.4588,  ..., -0.3569, -0.3176, -0.1216],
          [ 0.4275,  0.3725,  0.4196,  ..., -0.1843, -0.2078, -0.0745],
          ...,
          [-0.7490, -0.7569, -0.7569,  ..., -0.7647, -0.6078, -0.6314],
          [-0.7569, -0.7569, -0.7569,  ..., -0.6235, -0.3333, -0.4353],
          [-0.7647, -0.7647, -0.7647,  ..., -0.2078, -0.0275, -0.3333]]]]), tensor([1, 0, 4, 1])]
torch.Size([4, 758, 3, 3])
torch.Size([9096, 3])
torch.Size([9096, 553])
torch.Size([9096, 433])
torch.Size([9096, 10])
Process Process-1:
Traceback (most recent call last):
  File "/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/global/homes/d/danieltm/.local/cori/pytorchv1.2.0-gpu/lib/python3.6/site-packages/wandb/wandb_agent.py", line 64, in _start
    function()
  File "src/sweep.py", line 91, in train
    loss = criterion(outputs, labels)
  File "/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/torch/nn/modules/loss.py", line 916, in forward
    ignore_index=self.ignore_index, reduction=self.reduction)
  File "/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/torch/nn/functional.py", line 1995, in cross_entropy
    return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)
  File "/usr/common/software/pytorch/v1.2.0-gpu/lib/python3.6/site-packages/torch/nn/functional.py", line 1822, in nll_loss
    .format(input.size(0), target.size(0)))
ValueError: Expected input batch_size (9096) to match target batch_size (4).
